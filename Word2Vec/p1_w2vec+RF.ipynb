{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nikita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "nltk.download('stopwords')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../P1_train.csv\")\n",
    "test = pd.read_csv(\"../P1_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    736\n",
       "2    661\n",
       "0    263\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    303\n",
       "2    298\n",
       "0     82\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterWords(review):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",review)\n",
    "    words = text.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if not word in stops]\n",
    "    return(words)\n",
    "\n",
    "def tokenize(review, tokenizer):\n",
    "    sentences = tokenizer.tokenize(review.strip())\n",
    "    allSentences = []\n",
    "    for sentence in sentences:\n",
    "        if len(sentence)>0:\n",
    "            allSentences.append(filterWords(sentence))\n",
    "    return allSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for review in train[\"sentence\"]:\n",
    "    sentences += tokenize(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 100\n",
    "min_word_count = 1\n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 04:33:11: collecting all words and their counts\n",
      "INFO - 04:33:11: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 04:33:11: collected 11351 word types from a corpus of 41409 raw words and 1660 sentences\n",
      "INFO - 04:33:11: Loading a fresh vocabulary\n",
      "INFO - 04:33:11: effective_min_count=1 retains 11351 unique words (100% of original 11351, drops 0)\n",
      "INFO - 04:33:11: effective_min_count=1 leaves 41409 word corpus (100% of original 41409, drops 0)\n",
      "INFO - 04:33:11: deleting the raw counts dictionary of 11351 items\n",
      "INFO - 04:33:11: sample=0.001 downsamples 9 most-common words\n",
      "INFO - 04:33:11: downsampling leaves estimated 40861 word corpus (98.7% of prior 41409)\n",
      "INFO - 04:33:11: estimated required memory for 11351 words and 100 dimensions: 14756300 bytes\n",
      "INFO - 04:33:11: resetting layer weights\n",
      "INFO - 04:33:16: training model with 3 workers on 11351 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 04:33:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 04:33:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 04:33:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 04:33:16: EPOCH - 1 : training on 41409 raw words (40842 effective words) took 0.1s, 278275 effective words/s\n",
      "INFO - 04:33:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 04:33:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 04:33:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 04:33:16: EPOCH - 2 : training on 41409 raw words (40843 effective words) took 0.2s, 259068 effective words/s\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 04:33:17: EPOCH - 3 : training on 41409 raw words (40852 effective words) took 0.1s, 325277 effective words/s\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 04:33:17: EPOCH - 4 : training on 41409 raw words (40859 effective words) took 0.1s, 307056 effective words/s\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 04:33:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 04:33:17: EPOCH - 5 : training on 41409 raw words (40862 effective words) took 0.2s, 244365 effective words/s\n",
      "INFO - 04:33:17: training on a 207045 raw words (204258 effective words) took 0.8s, 257047 effective words/s\n",
      "WARNING - 04:33:17: under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, min_count=min_word_count, sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureVecs(words, model, num_features):\n",
    "    featureVec = np.zeros(num_features, dtype=\"float32\")\n",
    "    totalWords = 0\n",
    "    index2word_set = set(model.wv.index2word)    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            totalWords += 1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "    featureVec = np.divide(featureVec, totalWords)\n",
    "    return featureVec \n",
    "\n",
    "def getAvgFeatures(train_sentences, model, num_features):\n",
    "    l = len(train_sentences)\n",
    "    reviewFeatureVecs = np.zeros((l, num_features), dtype=\"float32\")\n",
    "    for i, review in enumerate(train_sentences):\n",
    "        reviewFeatureVecs[i] = getFeatureVecs(review, model, num_features)\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_sentences = []\n",
    "for sentence in train['sentence']:\n",
    "    train_sentences.append(filterWords(sentence))\n",
    "trainDataVecs = getAvgFeatures(train_sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "clean_test_reviews = []\n",
    "for review in test[\"sentence\"]:\n",
    "    clean_test_reviews.append(filterWords(review))\n",
    "    \n",
    "testDataVecs = getAvgFeatures(clean_test_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 1400)\n",
    "forest = forest.fit(trainDataVecs, train[\"label\"])\n",
    "result = forest.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5446559297218155\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test['label'], result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38527426067747766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test['label'], result, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted_label'] = pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('testing_output_word2vec.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/varun08/sentiment-analysis-using-word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
